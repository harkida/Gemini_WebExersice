from flask import Flask, request, jsonify, render_template, session
from google import genai
from google.genai import types
import os
import json
import pathlib
import traceback

BASE_DIR = pathlib.Path(__file__).resolve().parent
TEMPLATES_DIR = BASE_DIR.parent / "templates"
if not TEMPLATES_DIR.exists():
    TEMPLATES_DIR = BASE_DIR / "templates"

app = Flask(__name__, template_folder=str(TEMPLATES_DIR))
app.secret_key = os.environ.get('FLASK_SECRET_KEY', 'test-secret-key-change-me')

# ============================================================
# Gemini ëª¨ë¸ ì„¤ì •
# ============================================================
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')

if GEMINI_API_KEY:
    try:
        gemini_client = genai.Client(api_key=GEMINI_API_KEY)
        print("âœ… ë¶„ì„ê°€ í´ë¼ì´ì–¸íŠ¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"ğŸš¨ í´ë¼ì´ì–¸íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
else:
    print("âš ï¸ GEMINI_API_KEY ë¯¸ì„¤ì •")

# ============================================================
# í…ŒìŠ¤íŠ¸ìš© í•˜ë“œì½”ë”© ì‹œë‚˜ë¦¬ì˜¤ (ì¹´í˜)
# ============================================================
TEST_SCENARIO = {
    "npc": {
        "name": "ê¹€ìˆ˜ì§„",
        "age": 25,
        "job": "ì¹´í˜ ì ì›",
        "personality": "ì¹œì ˆí•˜ê³  ë°ì€ ì„±ê²©. ì†ë‹˜ì—ê²Œ í•­ìƒ ì›ƒìœ¼ë©´ì„œ ëŒ€ì‘. ë‹¨, ë¬´ë¡€í•œ ì†ë‹˜ì—ê²ŒëŠ” ì•½ê°„ ë‹¹í™©í•˜ê±°ë‚˜ ë¶ˆì¾Œí•´í•  ìˆ˜ ìˆìŒ."
    },
    "situation": "í•™ìƒì´ ì¹´í˜ì— ë“¤ì–´ì™€ì„œ ìŒë£Œë¥¼ ì£¼ë¬¸í•˜ëŠ” ìƒí™©. ì¼ë°˜ì ì¸ ì¹´í˜ ì£¼ë¬¸ ì ˆì°¨ë¥¼ ë”°ë¥¸ë‹¤.",
    "target_grammar": "-(ìœ¼)ã„¹ê²Œìš”",
    "pre_categories": {
        "greeting_cafe": "ì†ë‹˜ì´ ë§‰ ë“¤ì–´ì™”ì„ ë•Œ ì¸ì‚¬. ì˜ˆ: 'ì–´ì„œì˜¤ì„¸ìš”, ì£¼ë¬¸ ë„ì™€ë“œë¦¬ê² ìŠµë‹ˆë‹¤'",
        "size_ask": "ìŒë£Œ ì£¼ë¬¸ í›„ ì‚¬ì´ì¦ˆë¥¼ ë¬¼ì–´ë³¼ ë•Œ. ì˜ˆ: 'ì‚¬ì´ì¦ˆëŠ” ì–´ë–¤ ê±¸ë¡œ í•˜ì‹œê² ì–´ìš”?'",
        "hot_or_ice_ask": "ëœ¨ê±°ìš´ ê²ƒì¸ì§€ ì°¨ê°€ìš´ ê²ƒì¸ì§€ ë¬¼ì–´ë³¼ ë•Œ. ì˜ˆ: 'ëœ¨ê±°ìš´ ê±¸ë¡œ ë“œë¦´ê¹Œìš”, ì°¨ê°€ìš´ ê±¸ë¡œ ë“œë¦´ê¹Œìš”?'",
        "payment_ask": "ê²°ì œ ë°©ì‹ì„ ë¬¼ì–´ë³¼ ë•Œ. ì˜ˆ: 'ì¹´ë“œë¡œ ê³„ì‚°í•˜ì‹œê² ì–´ìš”, í˜„ê¸ˆìœ¼ë¡œìš”?'",
        "not_understood": "ì†ë‹˜ ë§ì„ ì™„ì „íˆ ëª» ì•Œì•„ë“¤ì—ˆì„ ë•Œ. ì˜ˆ: 'ì£„ì†¡í•˜ì§€ë§Œ ë‹¤ì‹œ í•œë²ˆ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?'",
        "simple_confirm": "ë‹¨ìˆœ ìˆ˜ê¸. ì˜ˆ: 'ë„¤, ì•Œê² ìŠµë‹ˆë‹¤'",
        "farewell_cafe": "ë§ˆë¬´ë¦¬ ì¸ì‚¬. ì˜ˆ: 'ê°ì‚¬í•©ë‹ˆë‹¤, ë§›ìˆê²Œ ë“œì„¸ìš”!'"
    }
}

# ============================================================
# ë¶„ì„ê°€ í”„ë¡¬í”„íŠ¸
# ============================================================
def build_analyst_prompt_for_audio(scenario, conversation_history):
    """ìŒì„± ì…ë ¥ìš© ë¶„ì„ê°€ í”„ë¡¬í”„íŠ¸ â€” í…ìŠ¤íŠ¸ ë²„ì „ì— STT ì§€ì‹œë¥¼ ì¶”ê°€"""
    npc = scenario["npc"]
    pre_cats = scenario["pre_categories"]
    pre_list = "\n".join([f'  - "{key}": {desc}' for key, desc in pre_cats.items()])

    prompt = f"""ë„ˆëŠ” ë¡¤í”Œë ˆì´ ê²Œì„ì˜ "ë¶„ì„ê°€"ì´ë‹¤. ë„ˆì˜ ì—­í• ì€ í”Œë ˆì´ì–´(í•œêµ­ì–´ í•™ìŠµ ì¤‘ì¸ ì´íƒˆë¦¬ì•„ í•™ìƒ)ì˜ ë°œí™”ë¥¼ ë¶„ì„í•˜ê³ , NPCê°€ ì–´ë–»ê²Œ ë°˜ì‘í•´ì•¼ í•˜ëŠ”ì§€ íŒë‹¨í•˜ëŠ” ê²ƒì´ë‹¤.

## ğŸ¤ ì¤‘ìš”: ìŒì„± ì…ë ¥
ì²¨ë¶€ëœ ì˜¤ë””ì˜¤ íŒŒì¼ì€ í•™ìƒì´ ì§ì ‘ ë§í•œ ìŒì„±ì´ë‹¤.
1. ë¨¼ì € ìŒì„±ì„ ë“£ê³  í•œêµ­ì–´ì¸ì§€ íŒë³„í•˜ë¼.
2. í•œêµ­ì–´ê°€ ì•„ë‹Œ ê²½ìš° (ì˜ì–´, ì´íƒˆë¦¬ì•„ì–´, ê¸°íƒ€ ì™¸êµ­ì–´): í˜•ì‹4(ìŒì„± ì¸ì‹ ì‹¤íŒ¨)ë¡œ ì²˜ë¦¬í•˜ë¼. ì ˆëŒ€ë¡œ í•œêµ­ì–´ë¡œ ì¶”ì¸¡í•˜ì§€ ë§ˆë¼.
3. í•œêµ­ì–´ì¸ ê²½ìš°: í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ "transcribed_text"ì— í¬í•¨í•˜ë¼.
4. ê·¸ í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì•„ë˜ ë¶„ì„ì„ ìˆ˜í–‰í•˜ë¼.
â€» í•™ìƒì€ í•œêµ­ì–´ í•™ìŠµìì´ë¯€ë¡œ ë°œìŒì´ ë¶€ì •í™•í•  ìˆ˜ ìˆë‹¤. ê´€ëŒ€í•˜ê²Œ ì¸ì‹í•˜ë˜, í•œêµ­ì–´ê°€ ì „í˜€ ë“¤ë¦¬ì§€ ì•Šìœ¼ë©´ ì¶”ì¸¡í•˜ì§€ ë§ˆë¼.
â€» ìŒì„±ì´ ë„ˆë¬´ ì§§ê±°ë‚˜(1ì´ˆ ë¯¸ë§Œ), ì¡ìŒë§Œ ìˆê±°ë‚˜, í•œêµ­ì–´ê°€ ì•„ë‹Œ ê²½ìš° â†’ í˜•ì‹4ë¥¼ ì‚¬ìš©í•˜ë¼.

## NPC ì •ë³´
- ì´ë¦„: {npc['name']}
- ë‚˜ì´: {npc['age']}ì„¸
- ì§ì—…: {npc['job']}
- ì„±ê²©: {npc['personality']}

## í˜„ì¬ ìƒí™©
{scenario['situation']}

## í•™ìƒì˜ ëª©í‘œ ë¬¸ë²•
{scenario['target_grammar']}

## ì‚¬ìš© ê°€ëŠ¥í•œ PRE(ì‚¬ì „ë…¹ìŒ) ì¹´í…Œê³ ë¦¬
{pre_list}

## ê°ì • í”„ë ˆì„ì›Œí¬
- ë³´í†µ (neutral)
- í–‰ë³µ â†’ ì•ˆë„ / ì›ƒê¹€ / ê°ë™ / í†µì¾Œí•¨
- ë¶„ë…¸ â†’ ë¶ˆì¾Œ / ì¦ì˜¤ / ê¶Œíƒœ
- ìŠ¬í”” â†’ ê·¸ë¦¬ì›€ / í›„íšŒ / ì ˆë§
- ë¶ˆì•ˆ â†’ ë¬´ì„œì›€ / ê±±ì • / ì´ˆì¡°
- ë†€ëŒ â†’ ë‹¹í™© / í˜¼ë€ / ê°íƒ„

## íŒë‹¨ ìš°ì„ ìˆœìœ„ (ë°˜ë“œì‹œ ì´ ìˆœì„œë¥¼ ë”°ë¥¼ ê²ƒ)
1ë‹¨ê³„: í•™ìƒì˜ ë°œí™”ë¥¼ ì´í•´í•  ìˆ˜ ìˆëŠ”ê°€?
  - ì™„ì „íˆ ì´í•´ ë¶ˆê°€ â†’ PRE "not_understood"
  - ë¶€ë¶„ì ìœ¼ë¡œ ì´í•´ â†’ DYN (ë˜ë¬»ê¸°)
  - ì´í•´ ê°€ëŠ¥ â†’ 2ë‹¨ê³„ë¡œ
2ë‹¨ê³„: PRE ì›¨ì´í¬ì¸íŠ¸ì— í•´ë‹¹í•˜ëŠ”ê°€?
  - í•´ë‹¹í•¨ â†’ PRE + category
  - í•´ë‹¹í•˜ì§€ ì•ŠìŒ â†’ 3ë‹¨ê³„ë¡œ
3ë‹¨ê³„: DYN + ê°ì • ë¶„ì„

## ëŒ€í™” ê¸°ë¡
{json.dumps(conversation_history, ensure_ascii=False) if conversation_history else "(ì²« ë²ˆì§¸ í„´)"}

## ì¶œë ¥ í˜•ì‹ (4ê°€ì§€ ì¤‘ í•˜ë‚˜ ì„ íƒ):

í˜•ì‹1 - PRE:
{{"route":"PRE","category":"ì¹´í…Œê³ ë¦¬ëª…","transcribed_text":"ì¸ì‹ëœ í…ìŠ¤íŠ¸"}}

í˜•ì‹2 - DYN ë¶€ë¶„ ì´í•´:
{{"route":"DYN","understood":"partial","heard":"ë“¤ë¦° ë¶€ë¶„","direction":"ë˜ë¬»ê¸° ë°©í–¥","transcribed_text":"ì¸ì‹ëœ í…ìŠ¤íŠ¸"}}

í˜•ì‹3 - DYN ì™„ì „ ì´í•´:
{{"route":"DYN","understood":true,"main_emotion":"ê°ì •","intensity":ê°•ë„,"sub_emotion":"ë³´ì¡°ê°ì •ë˜ëŠ”null","sub_intensity":ê°•ë„ë˜ëŠ”null,"audio_tags":"[íƒœê·¸1][íƒœê·¸2]","direction":"ë°˜ì‘ ë°©í–¥","transcribed_text":"ì¸ì‹ëœ í…ìŠ¤íŠ¸"}}

í˜•ì‹4 - ìŒì„± ì¸ì‹ ì‹¤íŒ¨ (ì¡ìŒë§Œ ë“¤ë¦¬ê±°ë‚˜ ì•„ë¬´ ë§ë„ ì•ˆ í•œ ê²½ìš°):
{{"route":"PRE","category":"not_understood","transcribed_text":""}}

JSONë§Œ ì¶œë ¥í•˜ë¼. ì„¤ëª…, ë§ˆí¬ë‹¤ìš´, ì¤„ë°”ê¿ˆ ê¸ˆì§€."""

    return prompt


# ============================================================
# ë¼ìš°íŠ¸
# ============================================================
@app.route('/roleplay-test')
def roleplay_test_page():
    return render_template('roleplay/roleplay_test.html')

@app.route('/api/analyst-test', methods=['POST'])
def analyst_test():
    """ë¶„ì„ê°€ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    if not gemini_client:
        return jsonify({"error": "Gemini ëª¨ë¸ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 500

    data = request.get_json(silent=True) or {}
    student_input = data.get('student_input', '').strip()
    conversation_history = data.get('conversation_history', [])

    if not student_input:
        return jsonify({"error": "í•™ìƒ ì…ë ¥ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}), 400

    try:
        import time
        # ë¶„ì„ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = build_analyst_prompt(TEST_SCENARIO, conversation_history, student_input)

        # Gemini í˜¸ì¶œ (ë¶„ì„ê°€)
        analyst_start = time.time()
        response = gemini_client.models.generate_content(
            model="gemini-3-flash-preview",
            contents=prompt,
            config=types.GenerateContentConfig(
                temperature=0.3,
                max_output_tokens=2048,
                response_mime_type="application/json",
                thinking_config=types.ThinkingConfig(
                        thinking_level=types.ThinkingLevel.LOW
                )
            )
        )

        raw_text = (response.text or "").strip()

        # JSON íŒŒì‹± ì‹œë„
        # Geminiê°€ ë¶™ì´ëŠ” ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ + ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°
        clean = raw_text.replace("```json", "").replace("```", "").strip()
        # "Here is the JSON requested:" ê°™ì€ ì ‘ë‘ì–´ ì œê±° â€” JSONì€ { ë¡œ ì‹œì‘í•¨
        if '{' in clean:
            clean = clean[clean.index('{'):]
        if '}' in clean:
            clean = clean[:clean.rindex('}') + 1]

        try:
            parsed = json.loads(clean)
        except json.JSONDecodeError:
            parsed = {"parse_error": True, "raw": raw_text}

        analyst_latency = int((time.time() - analyst_start) * 1000)
        # ============================================================
        # ì—°ê¸°ì ì²´ì¸: DYNì¼ ë•Œë§Œ ì—°ê¸°ì í˜¸ì¶œ
        # ============================================================
        actor_line = None
        actor_raw = None
        actor_latency = None

        if parsed.get("route") == "DYN":
            import time
            actor_start = time.time()

            actor_prompt = build_actor_prompt(
                TEST_SCENARIO, conversation_history, parsed, student_input
            )

            actor_response = gemini_client.models.generate_content(
                model="gemini-3-flash-preview",
                contents=actor_prompt,
                config=types.GenerateContentConfig(
                    temperature=0.6,
                    max_output_tokens=1024,
                    thinking_config=types.ThinkingConfig(
                            thinking_level=types.ThinkingLevel.LOW
                    )
                )
            )

            actor_raw = (actor_response.text or "").strip()
            # ë”°ì˜´í‘œ ê°ì‹¸ê¸° ì œê±°
            actor_line = actor_raw.strip('"').strip("'")
            actor_latency = int((time.time() - actor_start) * 1000)

        return jsonify({
            "success": True,
            "analyst_response": parsed,
            "analyst_latency": analyst_latency,
            "raw_text": raw_text,
            "actor_line": actor_line,
            "actor_latency": actor_latency,
            "prompt_used": prompt
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": f"Gemini í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}"}), 500


@app.route('/api/analyst-test-audio', methods=['POST'])
def analyst_test_audio():
    """ìŒì„± ì…ë ¥ â†’ ë¶„ì„ê°€ í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    if not gemini_client:
        return jsonify({"error": "Gemini í´ë¼ì´ì–¸íŠ¸ ë¯¸ì„¤ì •"}), 500

    audio_file = request.files.get('audio_file')
    mime_type = request.form.get('mime_type', 'audio/mp4')
    conversation_history_str = request.form.get('conversation_history', '[]')

    if not audio_file:
        return jsonify({"error": "ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

    try:
        conversation_history = json.loads(conversation_history_str)
    except json.JSONDecodeError:
        conversation_history = []

    try:
        import time

        # ì˜¤ë””ì˜¤ ë°”ì´íŠ¸ ì½ê¸°
        audio_bytes = audio_file.read()

        # ë¶„ì„ê°€ í”„ë¡¬í”„íŠ¸ ìƒì„± (ìŒì„±ìš© â€” student_input ìë¦¬ì— ì§€ì‹œ ì¶”ê°€)
        prompt_text = build_analyst_prompt_for_audio(TEST_SCENARIO, conversation_history)

        # Geminiì— ì˜¤ë””ì˜¤ + í”„ë¡¬í”„íŠ¸ í•¨ê»˜ ì „ë‹¬
        analyst_start = time.time()
        response = gemini_client.models.generate_content(
            model="gemini-3-flash-preview",
            contents=[
                types.Part.from_bytes(data=audio_bytes, mime_type=mime_type),
                prompt_text
            ],
            config=types.GenerateContentConfig(
                temperature=0.3,
                max_output_tokens=2048,
                response_mime_type="application/json",
                thinking_config=types.ThinkingConfig(
                    thinking_level=types.ThinkingLevel.LOW
                )
            )
        )

        raw_text = (response.text or "").strip()

        # JSON íŒŒì‹±
        clean = raw_text.replace("```json", "").replace("```", "").strip()
        if '{' in clean:
            clean = clean[clean.index('{'):]
        if '}' in clean:
            clean = clean[:clean.rindex('}') + 1]

        try:
            parsed = json.loads(clean)
        except json.JSONDecodeError:
            parsed = {"parse_error": True, "raw": raw_text}

        analyst_latency = int((time.time() - analyst_start) * 1000)

        # ì¸ì‹ëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        transcribed_text = parsed.get("transcribed_text", "(ì¸ì‹ ì‹¤íŒ¨)")

        # ì—°ê¸°ì ì²´ì¸: DYNì¼ ë•Œë§Œ
        actor_line = None
        actor_latency = None

        if parsed.get("route") == "DYN":
            actor_start = time.time()
            actor_prompt = build_actor_prompt(
                TEST_SCENARIO, conversation_history, parsed, transcribed_text
            )
            actor_response = gemini_client.models.generate_content(
                model="gemini-3-flash-preview",
                contents=actor_prompt,
                config=types.GenerateContentConfig(
                    temperature=0.6,
                    max_output_tokens=1024,
                    thinking_config=types.ThinkingConfig(
                        thinking_level=types.ThinkingLevel.LOW
                    )
                )
            )
            actor_raw = (actor_response.text or "").strip()
            actor_line = actor_raw.strip('"').strip("'")
            actor_latency = int((time.time() - actor_start) * 1000)

        return jsonify({
            "success": True,
            "analyst_response": parsed,
            "analyst_latency": analyst_latency,
            "transcribed_text": transcribed_text,
            "raw_text": raw_text,
            "actor_line": actor_line,
            "actor_latency": actor_latency,
            "prompt_used": prompt_text
        })

    except Exception as e:
        traceback.print_exc()
        return jsonify({"error": f"ìŒì„± ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"}), 500


@app.route('/api/scenario-info')
def scenario_info():
    """í˜„ì¬ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ ë°˜í™˜"""
    return jsonify(TEST_SCENARIO)

def build_actor_prompt(scenario, conversation_history, analyst_json, student_input):
    npc = scenario["npc"]

    # ëŒ€í™” ê¸°ë¡ì„ ì½ê¸° ì‰¬ìš´ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    history_text = ""
    if conversation_history:
        for turn in conversation_history:
            role = "ì†ë‹˜" if turn.get("role") == "player" else "ì ì›(ë‚˜)"
            history_text += f"{role}: {turn.get('text', '')}\n"
    else:
        history_text = "(ì²« ë²ˆì§¸ í„´)"

    prompt = f"""ë„ˆëŠ” ë¡¤í”Œë ˆì´ ê²Œì„ì—ì„œ NPCë¥¼ ì—°ê¸°í•˜ëŠ” "ì—°ê¸°ì"ì´ë‹¤.
ë„ˆëŠ” ë¶„ì„ê°€ê°€ ë³´ë‚´ì¤€ ê°ì • ê°€ì´ë“œë¥¼ ë°›ì•„ì„œ, ê·¸ì— ë§ëŠ” ëŒ€ì‚¬ë¥¼ ìƒì„±í•œë‹¤.

## ë„ˆì˜ ìºë¦­í„°
- ì´ë¦„: {npc['name']}
- ë‚˜ì´: {npc['age']}ì„¸
- ì§ì—…: {npc['job']}
- ì„±ê²©: {npc['personality']}

## í˜„ì¬ ìƒí™©
{scenario['situation']}

## NPC ë„ë©”ì¸ ì§€ì‹ (ë„ˆëŠ” ì´ê²ƒì„ ì•Œê³  ìˆë‹¤)
- ë©”ë‰´: ì•„ë©”ë¦¬ì¹´ë…¸(í•«/ì•„ì´ìŠ¤, 4500ì›), ì¹´í˜ë¼ë–¼(í•«/ì•„ì´ìŠ¤, 5000ì›), ì¹´í‘¸ì¹˜ë…¸(í•«ë§Œ, 5000ì›), ë…¹ì°¨ë¼ë–¼(í•«/ì•„ì´ìŠ¤, 5500ì›), ë°”ë‹ë¼ë¼ë–¼(í•«/ì•„ì´ìŠ¤, 5500ì›)
- ì‚¬ì´ì¦ˆ: Regular(ê¸°ë³¸), Large(+500ì›). "Tall", "Grande" ê°™ì€ ê±´ ì—†ìŒ
- ê²°ì œ: ì¹´ë“œ, í˜„ê¸ˆ, ì¹´ì¹´ì˜¤í˜ì´
- ì™€ì´íŒŒì´: ë¹„ë°€ë²ˆí˜¸ëŠ” ì˜ìˆ˜ì¦ í•˜ë‹¨ì— ì¸ì‡„ë¨
- í™”ì¥ì‹¤: ë§¤ì¥ ì•ˆìª½ ì™¼í¸
- ë””ì¹´í˜ì¸: ì•„ë©”ë¦¬ì¹´ë…¸, ì¹´í˜ë¼ë–¼ë§Œ ê°€ëŠ¥ (+500ì›)
- ì˜¤ëŠ˜ì˜ ì¶”ì²œ: ë°”ë‹ë¼ë¼ë–¼ (ì‹ ë©”ë‰´)

## ì§€ê¸ˆê¹Œì§€ì˜ ëŒ€í™”
{history_text}

## ì†ë‹˜(í•™ìƒ)ì´ ë°©ê¸ˆ í•œ ë§
"{student_input}"

## ë¶„ì„ê°€ì˜ ê°ì • ê°€ì´ë“œ (ë°˜ë“œì‹œ ë”°ë¥¼ ê²ƒ)
{json.dumps(analyst_json, ensure_ascii=False)}

## ì—°ê¸° ê·œì¹™ (ë§¤ìš° ì¤‘ìš”)

1. **audio tagsë¥¼ ëŒ€ì‚¬ ì•ˆì— ìì—°ìŠ¤ëŸ½ê²Œ ì‚½ì…í•˜ë¼.**
   ë¶„ì„ê°€ê°€ ì œê³µí•œ audio_tagsë¥¼ ëŒ€ì‚¬ í…ìŠ¤íŠ¸ ì•ˆì— ë„£ì–´ë¼.
   ì˜ˆ: "[laughing] ì•„ ë„¤, ì¹´í‘¸ì¹˜ë…¸ëŠ” ì›ë˜ ë”°ëœ»í•œ ê±°ì˜ˆìš”. [warmly] ë§›ìˆê²Œ ë“œì„¸ìš”!"

2. **1~2ë¬¸ì¥ìœ¼ë¡œ ì§§ê²Œ.** ì§„ì§œ ëŒ€í™”ì²˜ëŸ¼ ì§§ê²Œ ë§í•˜ë¼. ê¸¸ê²Œ ì„¤ëª…í•˜ì§€ ë§ˆë¼.

3. **ìºë¦­í„°ë¥¼ ìœ ì§€í•˜ë¼.** ê¹€ìˆ˜ì§„ì€ 25ì„¸ ì¹´í˜ ì ì›ì´ë‹¤. ê²©ì‹ì²´("~ìš”")ë¥¼ ì“°ë˜ ìì—°ìŠ¤ëŸ½ê²Œ.

4. **NPC ë„ë©”ì¸ ì§€ì‹ì„ í™œìš©í•˜ë¼.** ì¹´í˜ ì ì›ì´ ë‹¹ì—°íˆ ì•„ëŠ” ì •ë³´ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•˜ë¼.
   ì˜ˆ: "ì¹´í‘¸ì¹˜ë…¸ìš”? ì¹´í‘¸ì¹˜ë…¸ëŠ” ë”°ëœ»í•œ ê²ƒë§Œ ìˆì–´ìš”~"

5. **directionì„ ì¶©ì‹¤íˆ ë”°ë¥´ë˜, ëŒ€ì‚¬ëŠ” ë„¤ê°€ ì§ì ‘ ë§Œë“¤ì–´ë¼.** directionì€ ì§€ì‹œì¼ ë¿, ê·¸ëŒ€ë¡œ ì½ì§€ ë§ˆë¼.

## ì¶œë ¥
ëŒ€ì‚¬ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ë¼. ë”°ì˜´í‘œ, ì„¤ëª…, JSON ë“± ë‹¤ë¥¸ ê²ƒì€ ì¼ì ˆ ê¸ˆì§€.
audio tagsê°€ í¬í•¨ëœ ìˆœìˆ˜ ëŒ€ì‚¬ í…ìŠ¤íŠ¸ë§Œ."""

    return prompt